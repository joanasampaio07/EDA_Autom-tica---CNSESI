import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.preprocessing import StandardScaler
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

st.set_page_config(
    page_title="EDA AutomÃ¡tica - CNSESI",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Tema
st.markdown("""
    <style>
    .main {
        padding: 20px;
    }
    .metric-box {
        background-color: #f0f2f6;
        padding: 15px;
        border-radius: 10px;
    }
    </style>
""", unsafe_allow_html=True)

st.title("ğŸ“Š EDA AutomÃ¡tica - CNSESI")
st.markdown("**Sistema Completo de AnÃ¡lise ExploratÃ³ria de Dados**")
st.markdown("---")

# Sidebar
with st.sidebar:
    st.header("â„¹ï¸ Sobre")
    st.info("Sistema avanÃ§ado de AnÃ¡lise ExploratÃ³ria de Dados AutomÃ¡tica")
    st.markdown("---")
    st.markdown("**Desenvolvido por:** Joana Sampaio")
    st.markdown("**VersÃ£o:** 2.0")
    st.markdown("---")
    st.subheader("ğŸ“‹ Funcionalidades:")
    st.markdown("""
    - âœ… Suporte a mÃºltiplos formatos
    - âœ… AnÃ¡lise estatÃ­stica completa
    - âœ… VisualizaÃ§Ãµes avanÃ§adas
    - âœ… DetecÃ§Ã£o de outliers
    - âœ… AnÃ¡lise de correlaÃ§Ã£o
    - âœ… GeraÃ§Ã£o de relatÃ³rios
    """)

# Upload de arquivo
st.header("ğŸ“ Carregar Dados")
uploaded_file = st.file_uploader(
    "Selecione um arquivo (CSV, Excel, TXT, etc.)", 
    type=['csv', 'xlsx', 'xls', 'txt']
)

def read_file_with_encoding(uploaded_file, file_extension):
    """Tenta ler arquivo com diferentes encodings"""
    try:
        if file_extension in ['xlsx', 'xls']:
            try:
                import openpyxl
            except ImportError:
                st.error("âŒ Biblioteca openpyxl nÃ£o disponÃ­vel. Instalando...")
                import subprocess
                subprocess.check_call(['pip', 'install', 'openpyxl'])
                import openpyxl
            
            df = pd.read_excel(uploaded_file, engine='openpyxl')
            return df
            
        elif file_extension == 'csv':
            encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252', 'utf-16']
            for encoding in encodings:
                try:
                    df = pd.read_csv(uploaded_file, encoding=encoding)
                    return df
                except (UnicodeDecodeError, LookupError):
                    uploaded_file.seek(0)
                    continue
            return None
            
        elif file_extension == 'txt':
            encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252', 'utf-16']
            for encoding in encodings:
                try:
                    df = pd.read_csv(uploaded_file, sep='\t', encoding=encoding)
                    return df
                except (UnicodeDecodeError, LookupError):
                    uploaded_file.seek(0)
                    continue
            return None
        else:
            return None
            
    except Exception as e:
        st.error(f"âŒ Erro ao ler arquivo: {str(e)}")
        return None

if uploaded_file is not None:
    try:
        file_extension = uploaded_file.name.split('.')[-1].lower()
        df = read_file_with_encoding(uploaded_file, file_extension)
        
        if df is None:
            st.error("âŒ NÃ£o foi possÃ­vel ler o arquivo. Tente outro formato ou encoding.")
        else:
            # ===== SEÃ‡ÃƒO 1: INFORMAÃ‡Ã•ES GERAIS =====
            st.header("ğŸ“Š InformaÃ§Ãµes Gerais")
            col1, col2, col3, col4, col5 = st.columns(5)
            
            total_rows = len(df)
            total_cols = len(df.columns)
            missing_percent = (df.isnull().sum().sum() / (total_rows * total_cols)) * 100
            duplicates = df.duplicated().sum()
            memory_usage = df.memory_usage(deep=True).sum() / 1024**2
            
            with col1:
                st.metric("ğŸ“ˆ Linhas", f"{total_rows:,}")
            with col2:
                st.metric("ğŸ“‹ Colunas", total_cols)
            with col3:
                st.metric("ğŸ’¾ MemÃ³ria (MB)", f"{memory_usage:.2f}")
            with col4:
                st.metric("âš ï¸ Ausentes (%)", f"{missing_percent:.1f}%")
            with col5:
                st.metric("ğŸ”„ Duplicatas", duplicates)
            
            # ===== SEÃ‡ÃƒO 2: PREVIEW =====
            st.header("ğŸ‘€ Preview dos Dados")
            col1, col2 = st.columns(2)
            with col1:
                st.write("**Primeiras Linhas:**")
                st.dataframe(df.head(10), use_container_width=True)
            with col2:
                st.write("**EstatÃ­sticas BÃ¡sicas:**")
                st.write(f"- Shape: {df.shape}")
                st.write(f"- Colunas: {', '.join(df.columns.tolist())}")
                st.write(f"- Ãndice: {df.index.name if df.index.name else 'PadrÃ£o'}")
            
            # ===== SEÃ‡ÃƒO 3: TIPOS DE DADOS =====
            st.header("ğŸ” Tipos de Dados")
            data_types_list = []
            for col in df.columns:
                dtype = df[col].dtype
                is_numeric = pd.api.types.is_numeric_dtype(df[col])
                unique = df[col].nunique()
                missing = df[col].isnull().sum()
                
                data_types_list.append({
                    "Coluna": col,
                    "Tipo": "NumÃ©rico" if is_numeric else "Texto",
                    "Python Type": str(dtype),
                    "Ãšnicos": unique,
                    "Ausentes": missing,
                    "Preenchimento (%)": f"{((total_rows - missing) / total_rows * 100):.1f}%"
                })
            
            types_df = pd.DataFrame(data_types_list)
            st.dataframe(types_df, use_container_width=True)
            
            # ===== SEÃ‡ÃƒO 4: VALORES FALTANTES =====
            st.header("âš ï¸ AnÃ¡lise de Valores Faltantes")
            missing_data = []
            for col in df.columns:
                missing_count = df[col].isnull().sum()
                if missing_count > 0:
                    missing_pct = (missing_count / total_rows) * 100
                    missing_data.append({
                        "Coluna": col,
                        "Faltantes": missing_count,
                        "Percentual": f"{missing_pct:.2f}%"
                    })
            
            if missing_data:
                missing_df = pd.DataFrame(missing_data)
                st.dataframe(missing_df, use_container_width=True, hide_index=True)
                
                # GrÃ¡fico de valores faltantes
                fig_missing = go.Figure(data=[
                    go.Bar(y=[d["Coluna"] for d in missing_data], 
                           x=[d["Faltantes"] for d in missing_data],
                           orientation='h',
                           marker_color='#ef553b')
                ])
                fig_missing.update_layout(
                    title="Contagem de Valores Faltantes por Coluna",
                    xaxis_title="Quantidade Faltante",
                    yaxis_title="Coluna",
                    height=400
                )
                st.plotly_chart(fig_missing, use_container_width=True)
            else:
                st.success("âœ… Sem valores faltantes!")
            
            # ===== SEÃ‡ÃƒO 5: DUPLICATAS =====
            st.header("ğŸ”„ AnÃ¡lise de Duplicatas")
            if duplicates > 0:
                st.warning(f"âš ï¸ Encontradas {duplicates} linhas duplicadas!")
                if st.checkbox("Mostrar linhas duplicadas"):
                    st.dataframe(df[df.duplicated(keep=False)].sort_values(by=list(df.columns)), use_container_width=True)
            else:
                st.success("âœ… Sem linhas duplicadas!")
            
            # ===== SEÃ‡ÃƒO 6: COLUNAS NUMÃ‰RICAS =====
            numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
            categorical_columns = df.select_dtypes(include=['object']).columns.tolist()
            
            if len(numeric_columns) > 0:
                st.header("ğŸ“ˆ AnÃ¡lise de Colunas NumÃ©ricas")
                
                # EstatÃ­sticas descritivas
                st.subheader("EstatÃ­sticas Descritivas")
                stats_df = df[numeric_columns].describe().round(4)
                st.dataframe(stats_df, use_container_width=True)
                
                # DistribuiÃ§Ãµes
                st.subheader("ğŸ“Š DistribuiÃ§Ãµes")
                cols_per_row = 2
                for i in range(0, len(numeric_columns), cols_per_row):
                    cols = st.columns(cols_per_row)
                    for j, col_idx in enumerate(range(i, min(i + cols_per_row, len(numeric_columns)))):
                        col = numeric_columns[col_idx]
                        with cols[j]:
                            fig = px.histogram(df, x=col, nbins=30, 
                                             title=f"DistribuiÃ§Ã£o: {col}",
                                             marginal="box")
                            fig.update_layout(height=400)
                            st.plotly_chart(fig, use_container_width=True)
                
                # Box plots
                st.subheader("ğŸ“¦ Box Plots")
                cols_per_row = 2
                for i in range(0, len(numeric_columns), cols_per_row):
                    cols = st.columns(cols_per_row)
                    for j, col_idx in enumerate(range(i, min(i + cols_per_row, len(numeric_columns)))):
                        col = numeric_columns[col_idx]
                        with cols[j]:
                            fig = go.Figure(data=[go.Box(y=df[col], name=col)])
                            fig.update_layout(title=f"Box Plot: {col}", height=400)
                            st.plotly_chart(fig, use_container_width=True)
                
                # DetecÃ§Ã£o de Outliers
                st.subheader("ğŸ¯ DetecÃ§Ã£o de Outliers (IQR)")
                outlier_info = []
                for col in numeric_columns:
                    Q1 = df[col].quantile(0.25)
                    Q3 = df[col].quantile(0.75)
                    IQR = Q3 - Q1
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    outliers = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()
                    
                    outlier_info.append({
                        "Coluna": col,
                        "Q1": f"{Q1:.4f}",
                        "Q3": f"{Q3:.4f}",
                        "IQR": f"{IQR:.4f}",
                        "Outliers": outliers,
                        "% Outliers": f"{(outliers/total_rows*100):.2f}%"
                    })
                
                st.dataframe(pd.DataFrame(outlier_info), use_container_width=True, hide_index=True)
                
                # CorrelaÃ§Ã£o
                if len(numeric_columns) > 1:
                    st.subheader("ğŸ”— Matriz de CorrelaÃ§Ã£o")
                    corr_matrix = df[numeric_columns].corr()
                    fig_corr = px.imshow(corr_matrix, 
                                        color_continuous_scale="RdBu",
                                        zmin=-1, zmax=1,
                                        title="Matriz de CorrelaÃ§Ã£o",
                                        labels=dict(color="CorrelaÃ§Ã£o"))
                    st.plotly_chart(fig_corr, use_container_width=True)
                    
                    # CorrelaÃ§Ãµes mais fortes
                    st.subheader("Top CorrelaÃ§Ãµes")
                    corr_pairs = []
                    for i in range(len(corr_matrix.columns)):
                        for j in range(i+1, len(corr_matrix.columns)):
                            corr_pairs.append({
                                "Coluna 1": corr_matrix.columns[i],
                                "Coluna 2": corr_matrix.columns[j],
                                "CorrelaÃ§Ã£o": f"{corr_matrix.iloc[i, j]:.4f}"
                            })
                    
                    corr_df = pd.DataFrame(corr_pairs).sort_values(
                        by="CorrelaÃ§Ã£o", 
                        key=abs, 
                        ascending=False
                    ).head(10)
                    st.dataframe(corr_df, use_container_width=True, hide_index=True)
            
            # ===== SEÃ‡ÃƒO 7: COLUNAS CATEGÃ“RICAS =====
            if len(categorical_columns) > 0:
                st.header("ğŸ“‚ AnÃ¡lise de Colunas CategÃ³ricas")
                
                for col in categorical_columns[:5]:  # Limitar a 5 colunas
                    st.subheader(f"Coluna: {col}")
                    col1, col2 = st.columns([1, 1])
                    
                    with col1:
                        value_counts = df[col].value_counts().head(10)
                        fig = px.bar(value_counts, 
                                    title=f"Top 10 Valores: {col}",
                                    labels={"index": col, "value": "Contagem"})
                        fig.update_layout(height=400)
                        st.plotly_chart(fig, use_container_width=True)
                    
                    with col2:
                        st.write("**Resumo EstatÃ­stico:**")
                        st.write(f"- Total de valores Ãºnicos: {df[col].nunique()}")
                        st.write(f"- Valor mais comum: {df[col].mode()[0] if len(df[col].mode()) > 0 else 'N/A'}")
                        st.write(f"- FrequÃªncia do mais comum: {df[col].value_counts().iloc[0] if len(df[col].value_counts()) > 0 else 'N/A'}")
                        st.write(f"- Valores ausentes: {df[col].isnull().sum()}")
            
            # ===== SEÃ‡ÃƒO 8: RELATÃ“RIO PARA DOWNLOAD =====
            st.header("ğŸ“„ Gerar RelatÃ³rio")
            
            report_content = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          RELATÃ“RIO DE ANÃLISE EXPLORATÃ“RIA DE DADOS            â•‘
â•‘                  EDA AutomÃ¡tica - CNSESI                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

INFORMAÃ‡Ã•ES GERAIS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Arquivo: {uploaded_file.name}
Data da AnÃ¡lise: {pd.Timestamp.now().strftime('%d/%m/%Y %H:%M:%S')}
Analista: Joana Sampaio

DIMENSÃ•ES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total de Linhas: {total_rows:,}
Total de Colunas: {total_cols}
MemÃ³ria Utilizada: {memory_usage:.2f} MB
Linhas Duplicadas: {duplicates}
Percentual de Dados Faltantes: {missing_percent:.2f}%

TIPOS DE DADOS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{types_df.to_string(index=False)}

VALORES FALTANTES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{pd.DataFrame(missing_data).to_string(index=False) if missing_data else 'Nenhum valor faltante encontrado!'}

ESTATÃSTICAS DESCRITIVAS (COLUNAS NUMÃ‰RICAS)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{df[numeric_columns].describe().to_string() if numeric_columns else 'Sem colunas numÃ©ricas'}

COLUNAS CATEGÃ“RICAS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
            
            for col in categorical_columns[:5]:
                report_content += f"\n{col}:\n{df[col].value_counts().to_string()}\n"
            
            report_content += f"""

CONCLUSÃ•ES E RECOMENDAÃ‡Ã•ES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ“ AnÃ¡lise concluÃ­da com sucesso
âœ“ Total de registros analisados: {total_rows:,}
âœ“ Total de variÃ¡veis: {total_cols}
"""
            
            if missing_percent > 10:
                report_content += "\nâš ï¸ ATENÃ‡ÃƒO: Percentual elevado de dados faltantes (>10%)"
            
            if duplicates > 0:
                report_content += f"\nâš ï¸ ATENÃ‡ÃƒO: {duplicates} linhas duplicadas encontradas"
            
            report_content += """

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RelatÃ³rio gerado automaticamente pelo Sistema EDA AutomÃ¡tica
Â© 2025 Joana Sampaio
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
            
            st.download_button(
                label="ğŸ“¥ Baixar RelatÃ³rio Completo (TXT)",
                data=report_content,
                file_name=f"relatorio_eda_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain"
            )
            
            # Exportar dados processados
            csv_data = df.to_csv(index=False)
            st.download_button(
                label="ğŸ’¾ Exportar Dados em CSV",
                data=csv_data,
                file_name=f"dados_processados_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
    
    except Exception as e:
        st.error(f"âŒ Erro ao processar: {str(e)}")

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center'>
    <p><strong>Â© 2025 Joana Sampaio - EDA AutomÃ¡tica CNSESI</strong></p>
    <p><small>Sistema de AnÃ¡lise ExploratÃ³ria de Dados v2.0</small></p>
</div>
""", unsafe_allow_html=True)
